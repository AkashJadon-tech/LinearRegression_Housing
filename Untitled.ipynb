{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e18a30-4677-4bc3-9d5c-a1c6c73ea60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Most of the code is copied from eng_fra_seq2seq_basic_v1 just modified for attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f70f5d-bd9e-4cdf-a959-29b5b2610b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02ffa150-c04e-484e-911f-c724ceecb2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "\n",
    "class BahdanauAttention(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = Dense(units)\n",
    "        self.W2 = Dense(units)\n",
    "        self.V = Dense(1)\n",
    "    \n",
    "    def call(self, query, values):\n",
    "        # query shape: (batch_size, hidden_size)\n",
    "        # values shape: (batch_size, seq_len, hidden_size)\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(query_with_time_axis)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1242d256-a0ed-49e2-81f6-3bae468f09c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionConcatLayer(Layer):\n",
    "    def __init__(self, lstm_units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = BahdanauAttention(lstm_units) \n",
    "    def call(self, decoder_outputs, encoder_outputs):\n",
    "        #decoder_outputs(batch, tgt_seq_len, lstm_units)\n",
    "        def apply_attention(dec_t):\n",
    "            # dec_t-shape (batch, lstm_units) (for single time step)\n",
    "            context_vector, _ = self.attention(dec_t, encoder_outputs)\n",
    "            return context_vector\n",
    "        #swap to time-major for map_fn(tgt_seq_len, batch, lstm_units)\n",
    "        decoder_outputs_time_major = tf.transpose(decoder_outputs, [1, 0, 2])\n",
    "        #compute context vector for each decoder timestep (returns: (tgt_seq_len, batch, lstm_units))\n",
    "        context_seq_time_major = tf.map_fn(\n",
    "            lambda dec_t: apply_attention(dec_t), \n",
    "            decoder_outputs_time_major, \n",
    "            fn_output_signature=tf.float32\n",
    "        )\n",
    "        #return to batch-major(batch, tgt_seq_len, lstm_units)\n",
    "        context_sequence = tf.transpose(context_seq_time_major, [1, 0, 2])\n",
    "        combined = Concatenate(axis=-1)([decoder_outputs, context_sequence])\n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b556521b-e37b-4cc9-8e8f-e411584472d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we load our data by giving path as well as max. no of samples\n",
    "def load_data(path , num_samples=10000):\n",
    "    #open the txt file split by space\n",
    "    with open(path , 'r' , encoding ='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    #separately store input and target text\n",
    "    for line in lines[:num_samples]:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        #now here the given dataset is french to english but i want eng to french trans so careful with the order\n",
    "        eng , fra = parts[0] , parts[1]\n",
    "        #add start and end for decoder\n",
    "        target_text = \"<start> \" + fra + \" <end>\"\n",
    "        input_texts.append(eng)\n",
    "        target_texts.append(target_text)\n",
    "        \n",
    "    return input_texts, target_texts\n",
    "\n",
    "input_texts, target_texts = load_data('fra.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b3c60fd-371d-4bc0-a0fb-3fa3f26ed24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sentences):\n",
    "    #convert in lowercase\n",
    "    sentences =  [s.lower() for s in sentences]\n",
    "    #remove everything except letters , digits , white spaces , and <>(remember the <start>)\n",
    "    #dont forget ^ this its the negation symbol i forgot and spend 30 minutes looking for bug\n",
    "    sentences = [re.sub(r\"[^a-zA-Z0-9<>\\s]\", \"\", s) for s in sentences]\n",
    "    return sentences\n",
    "input_texts = preprocess_text(input_texts)\n",
    "target_texts = preprocess_text(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5502d24e-cdc4-4e38-91d6-bec56be03d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize output\n",
    "#as we have already cleaned the text filter is off('' - do not remove anything)\n",
    "input_tokenizer = Tokenizer(filters = '')\n",
    "#go through all sentences and build a word-index vocab\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "#use the vocab and replce each word with its integer ID\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
    "#extract the word to index vocab or dict. for future uses\n",
    "input_word_index = input_tokenizer.word_index\n",
    "#find the max.sequence length\n",
    "max_input_len = max(len(seq) for seq in input_sequences)\n",
    "#pad with 0 if length is lower than max length\n",
    "encoder_input_data = pad_sequences(input_sequences , maxlen = max_input_len ,padding='post')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b478e039-0107-4211-9c82-18f346a4deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize output\n",
    "#No comments as everything is same as above\n",
    "target_tokenizer = Tokenizer(filters='')\n",
    "target_tokenizer.fit_on_texts(target_texts)\n",
    "target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n",
    "target_word_index = target_tokenizer.word_index\n",
    "max_target_len = max(len(seq) for seq in target_sequences)\n",
    "decoder_input_data = pad_sequences(target_sequences, maxlen=max_target_len,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b51cb58-4d6b-420c-b40f-98b0921741bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating decoder targets\n",
    "\n",
    "#create a numpy array of same shape as decoder_input_data\n",
    "decoder_target_data = np.zeros_like(decoder_input_data)\n",
    "#now we take all the columns from 1 to end from decoder_input_data and fill it in decoder_target_data from 0 to end - 1 \n",
    "#so basically we shifted left\n",
    "decoder_target_data[:,:-1] = decoder_input_data[:, 1:]\n",
    "#well this is actually not necessary but i still did that just to be safe , it does nothing but make sure last value is zero\n",
    "decoder_target_data[:, -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dac0263-f829-4f3a-96ad-8160d76036f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n",
      "4566\n"
     ]
    }
   ],
   "source": [
    "#embedding dimensions\n",
    "embedding_dim = 256 \n",
    "#LSTM hidden units\n",
    "lstm_units = 512\n",
    "#vocab size , +1 for padding token\n",
    "input_vocab_size = len(input_word_index)+1\n",
    "target_vocab_size = len(target_word_index)+1\n",
    "print(input_vocab_size)\n",
    "print(target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4a4a3b4-381e-4f6e-bf06-9debdd717640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder Model\n",
    "#encoder inputs\n",
    "encoder_inputs = Input(shape = (None , ))\n",
    "#embedding layer take encoder inputs of size vocab size as defined above and embed them and convert into dimensions of embedding_dim\n",
    "enc_emb = Embedding(input_vocab_size ,embedding_dim , mask_zero = True)(encoder_inputs)\n",
    "#a LSTM layer with hidden units = lstm_units and we want each hidden state as well as cell state so return_state is true and return_sequence is true\n",
    "encoder_outputs , state_h , state_c = LSTM(lstm_units, return_sequences = True, return_state = True)(enc_emb)\n",
    "#store the stats\n",
    "encoder_states = [state_h , state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f0db32e-3eb4-4e6d-a231-fb3d569b4c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:965: UserWarning: Layer 'attention_concat_layer_1' (of type AttentionConcatLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Decoder Model\n",
    "decoder_inputs = Input(shape = (None , ))\n",
    "decoder_emb_layer = Embedding(target_vocab_size, embedding_dim, mask_zero=True, name='dec_emb')\n",
    "dec_emb = decoder_emb_layer(decoder_inputs)\n",
    "#just defining the LSTM layer and in addition to states we want output at each state/time step so return_sequence = True\n",
    "decoder_lstm = LSTM(lstm_units,return_sequences = True, return_state = True)\n",
    "#get the outputs by giving dec_emb as input and passing encoder's states as initial states\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = encoder_states)\n",
    "# Attention application (replace tf.map_fn/transpose with this)\n",
    "attention_concat = AttentionConcatLayer(lstm_units)\n",
    "decoder_combined_context = attention_concat(decoder_outputs, encoder_outputs)\n",
    "#final output dense layer applied to each time step (TimeDistributed)\n",
    "decoder_dense = TimeDistributed(Dense(target_vocab_size, activation='softmax'))\n",
    "decoder_outputs_final = decoder_dense(decoder_combined_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a72aab53-4285-4abc-95fc-24288972f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Model\n",
    "#combined model with teacher forcing\n",
    "model = Model([encoder_inputs,decoder_inputs],decoder_outputs)\n",
    "#we are using 'sparse_categorical_crossentropy' cause we didnt one-hot encode targets\n",
    "model.compile(optimizer = 'adam' , loss ='sparse_categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb280977-cf6b-49d3-9139-fe13cb9b8595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">517,632</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec_emb (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168,896</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)] │                 │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ dec_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)] │                 │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>] │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m517,632\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_2 (\u001b[38;5;33mNotEqual\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec_emb (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m1,168,896\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                 │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),       │       \u001b[38;5;34m1,574,912\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)] │                 │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                 │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),       │       \u001b[38;5;34m1,574,912\u001b[0m │ dec_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)] │                 │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m] │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,836,352</span> (18.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,836,352\u001b[0m (18.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,836,352</span> (18.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,836,352\u001b[0m (18.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets check our model \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1feeb2e9-9017-4833-be2f-8a20afac2315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_44484\\2680249506.py\", line 3, in <module>\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 377, in fit\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 220, in function\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 114, in one_step_on_data\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 61, in train_step\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 383, in _compute_loss\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 351, in compute_loss\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 690, in __call__\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 699, in call\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 67, in __call__\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 33, in call\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 2330, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 2000, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 753, in sparse_categorical_crossentropy\n\nReceived a label value of 3716 which is outside the valid range of [0, 512).  Label values: 8 2770 2 0 0 0 0 0 0 0 0 0 11 1080 12 17 2623 2 0 0 0 0 0 0 8 64 3716 2 0 0 0 0 0 0 0 0 32 3247 2 0 0 0 0 0 0 0 0 0 570 2 0 0 0 0 0 0 0 0 0 0 13 206 2 0 0 0 0 0 0 0 0 0 3 18 72 303 2 0 0 0 0 0 0 0 4 1615 2 0 0 0 0 0 0 0 0 0 21 131 120 2 0 0 0 0 0 0 0 0 41 762 2 0 0 0 0 0 0 0 0 0 396 78 2 0 0 0 0 0 0 0 0 0 3 14 5 10 199 2 0 0 0 0 0 0 6 53 2 0 0 0 0 0 0 0 0 0 2350 2 0 0 0 0 0 0 0 0 0 0 181 604 379 2 0 0 0 0 0 0 0 0 1526 2 0 0 0 0 0 0 0 0 0 0 541 2 0 0 0 0 0 0 0 0 0 0 11 788 2 0 0 0 0 0 0 0 0 0 55 257 2 0 0 0 0 0 0 0 0 0 604 719 2 0 0 0 0 0 0 0 0 0 1779 2 0 0 0 0 0 0 0 0 0 0 6 19 136 3008 2 0 0 0 0 0 0 0 4 9 12 587 2 0 0 0 0 0 0 0 14 1071 10 2 0 0 0 0 0 0 0 0 4 9 300 2 0 0 0 0 0 0 0 0 3573 2 0 0 0 0 0 0 0 0 0 0 923 12 922 2 0 0 0 0 0 0 0 0 15 27 324 2 0 0 0 0 0 0 0 0 95 431 12 15 2 0 0 0 0 0 0 0 1500 140 2 0 0 0 0 0 0 0 0 0 3 269 110 2 0 0 0 0 0 0 0 0 32 3249 2 0 0 0 0 0 0 0 0 0 2776 91 2 0 0 0 0 0 0 0 0 0 7 616 4 2 0 0 0 0 0 0 0 0 1921 2 0 0 0 0 0 0 0 0 0 0 13 17 826 2 0 0 0 0 0 0 0 0 70 1191 2 0 0 0 0 0 0 0 0 0 32 2793 2 0 0 0 0 0 0 0 0 0 3 18 5 307 744 2 0 0 0 0 0 0 31 209 2 0 0 0 0 0 0 0 0 0 11 97 2 0 0 0 0 0 0 0 0 0 128 109 7 2 0 0 0 0 0 0 0 0 6 717 2 0 0 0 0 0 0 0 0 0 113 3176 2 0 0 0 0 0 0 0 0 0 4 15 800 16 317 2 0 0 0 0 0 0 2417 2 0 0 0 0 0 0 0 0 0 0 79 12 279 2 0 0 0 0 0 0 0 0 276 384 2 0 0 0 0 0 0 0 0 0 3 5 3422 2 0 0 0 0 0 0 0 0 6 3012 2 0 0 0 0 0 0 0 0 0 4 69 31 3667 2 0 0 0 0 0 0 0 3 269 297 2 0 0 0 0 0 0 0 0 11 787 2 0 0 0 0 0 0 0 0 0 3 5 421 2 0 0 0 0 0 0 0 0 11 51 2639 2 0 0 0 0 0 0 0 0 4 394 2 0 0 0 0 0 0 0 0 0 2297 2 0 0 0 0 0 0 0 0 0 0 32 763 2 0 0 0 0 0 0 0 0 0 13 17 339 2 0 0 0 0 0 0 0 0 3 5 3482 2 0 0 0 0 0 0 0 0 3558 2 0 0 0 0 0 0 0 0 0 0 35 18 1946 2 0 0 0 0 0 0 0 0 13 1830 2 0 0 0 0 0 0 0 0 0 15 27 23 2789 2 0 0 0 0 0 0 0\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_8502]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Train the Model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#... maens all the dimensions\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit([encoder_input_data,decoder_input_data], decoder_target_data[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,np\u001b[38;5;241m.\u001b[39mnewaxis], \n\u001b[0;32m      4\u001b[0m                     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m      5\u001b[0m                    validation_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_44484\\2680249506.py\", line 3, in <module>\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 377, in fit\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 220, in function\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 114, in one_step_on_data\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 61, in train_step\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 383, in _compute_loss\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 351, in compute_loss\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 690, in __call__\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 699, in call\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 67, in __call__\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 33, in call\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 2330, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 2000, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 753, in sparse_categorical_crossentropy\n\nReceived a label value of 3716 which is outside the valid range of [0, 512).  Label values: 8 2770 2 0 0 0 0 0 0 0 0 0 11 1080 12 17 2623 2 0 0 0 0 0 0 8 64 3716 2 0 0 0 0 0 0 0 0 32 3247 2 0 0 0 0 0 0 0 0 0 570 2 0 0 0 0 0 0 0 0 0 0 13 206 2 0 0 0 0 0 0 0 0 0 3 18 72 303 2 0 0 0 0 0 0 0 4 1615 2 0 0 0 0 0 0 0 0 0 21 131 120 2 0 0 0 0 0 0 0 0 41 762 2 0 0 0 0 0 0 0 0 0 396 78 2 0 0 0 0 0 0 0 0 0 3 14 5 10 199 2 0 0 0 0 0 0 6 53 2 0 0 0 0 0 0 0 0 0 2350 2 0 0 0 0 0 0 0 0 0 0 181 604 379 2 0 0 0 0 0 0 0 0 1526 2 0 0 0 0 0 0 0 0 0 0 541 2 0 0 0 0 0 0 0 0 0 0 11 788 2 0 0 0 0 0 0 0 0 0 55 257 2 0 0 0 0 0 0 0 0 0 604 719 2 0 0 0 0 0 0 0 0 0 1779 2 0 0 0 0 0 0 0 0 0 0 6 19 136 3008 2 0 0 0 0 0 0 0 4 9 12 587 2 0 0 0 0 0 0 0 14 1071 10 2 0 0 0 0 0 0 0 0 4 9 300 2 0 0 0 0 0 0 0 0 3573 2 0 0 0 0 0 0 0 0 0 0 923 12 922 2 0 0 0 0 0 0 0 0 15 27 324 2 0 0 0 0 0 0 0 0 95 431 12 15 2 0 0 0 0 0 0 0 1500 140 2 0 0 0 0 0 0 0 0 0 3 269 110 2 0 0 0 0 0 0 0 0 32 3249 2 0 0 0 0 0 0 0 0 0 2776 91 2 0 0 0 0 0 0 0 0 0 7 616 4 2 0 0 0 0 0 0 0 0 1921 2 0 0 0 0 0 0 0 0 0 0 13 17 826 2 0 0 0 0 0 0 0 0 70 1191 2 0 0 0 0 0 0 0 0 0 32 2793 2 0 0 0 0 0 0 0 0 0 3 18 5 307 744 2 0 0 0 0 0 0 31 209 2 0 0 0 0 0 0 0 0 0 11 97 2 0 0 0 0 0 0 0 0 0 128 109 7 2 0 0 0 0 0 0 0 0 6 717 2 0 0 0 0 0 0 0 0 0 113 3176 2 0 0 0 0 0 0 0 0 0 4 15 800 16 317 2 0 0 0 0 0 0 2417 2 0 0 0 0 0 0 0 0 0 0 79 12 279 2 0 0 0 0 0 0 0 0 276 384 2 0 0 0 0 0 0 0 0 0 3 5 3422 2 0 0 0 0 0 0 0 0 6 3012 2 0 0 0 0 0 0 0 0 0 4 69 31 3667 2 0 0 0 0 0 0 0 3 269 297 2 0 0 0 0 0 0 0 0 11 787 2 0 0 0 0 0 0 0 0 0 3 5 421 2 0 0 0 0 0 0 0 0 11 51 2639 2 0 0 0 0 0 0 0 0 4 394 2 0 0 0 0 0 0 0 0 0 2297 2 0 0 0 0 0 0 0 0 0 0 32 763 2 0 0 0 0 0 0 0 0 0 13 17 339 2 0 0 0 0 0 0 0 0 3 5 3482 2 0 0 0 0 0 0 0 0 3558 2 0 0 0 0 0 0 0 0 0 0 35 18 1946 2 0 0 0 0 0 0 0 0 13 1830 2 0 0 0 0 0 0 0 0 0 15 27 23 2789 2 0 0 0 0 0 0 0\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_8502]"
     ]
    }
   ],
   "source": [
    "#Train the Model\n",
    "#... maens all the dimensions\n",
    "history = model.fit([encoder_input_data,decoder_input_data], decoder_target_data[...,np.newaxis], \n",
    "                    batch_size = 64, epochs = 30,\n",
    "                   validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff3371f-11e0-4631-adb4-9998ff5b81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference encoder model- just takes input and gives out hidden states\n",
    "encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])\n",
    "#Decoder setup\n",
    "decoder_state_input_h = Input(shape=(lstm_units,))\n",
    "decoder_state_input_c = Input(shape=(lstm_units,))\n",
    "decoder_hidden_state_input = Input(shape=(max_input_len, lstm_units))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "#single step decoder input token (1 timestep)\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "dec_emb2 = decoder_emb_layer(decoder_inputs_single)\n",
    "#run the decoder LSTM for a single timestep with passed states\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "\n",
    "#compute attention context vector based on decoder output and encoder hidden states\n",
    "attention_layer = BahdanauAttention(lstm_units)\n",
    "context_vector2, attention_weights2 = attention_layer(decoder_outputs2[:, 0, :], decoder_hidden_state_input)\n",
    "#expand dims for concatenation to match decoder_outputs2 shape\n",
    "context_vector2 = tf.expand_dims(context_vector2, 1)\n",
    "decoder_combined_context2 = Concatenate(axis=-1)([decoder_outputs2, context_vector2])\n",
    "\n",
    "#final output dense layer for next word prediction\n",
    "decoder_outputs2 = decoder_dense(decoder_combined_context2)\n",
    "\n",
    "#final inference decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_single, decoder_hidden_state_input] + decoder_states_inputs,\n",
    "    [decoder_outputs2, state_h2, state_c2, attention_weights2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67929703-c2f0-47fc-9fc1-2b91968eebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_index = {i: word for word, i in target_tokenizer.word_index.items()}\n",
    "reverse_target_index[0] = ''\n",
    "target_index_word = target_tokenizer.word_index\n",
    "start_token = target_index_word['<start>']\n",
    "end_token = target_index_word['<end>']\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    #encode the input and get encoder outputs and states\n",
    "    enc_outs, state_h, state_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = start_token\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c, _ = decoder_model.predict([target_seq, enc_outs, state_h, state_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = reverse_target_index.get(sampled_token_index, '')\n",
    "        if sampled_word == '<end>' or len(decoded_sentence) > max_target_len:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence.append(sampled_word)\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        state_h, state_c = h, c\n",
    "    \n",
    "    return ' '.join(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b69de-0e8d-4067-81a2-73c3dd29034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check\n",
    "def predict_sample(index):\n",
    "    input_seq = encoder_input_data[index:index+1]\n",
    "    decoded = decode_sequence(input_seq)\n",
    "    print(\"Input:\", input_texts[index])\n",
    "    print(\"Target:\", target_texts[index])\n",
    "    print(\"Predicted:\", decoded)\n",
    "\n",
    "\n",
    "predict_sample(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c73c28d-d49b-4632-8c2b-124e0a51a05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets translate and check 5 sentences\n",
    "def predict_samples(start_index, num_samples=5):\n",
    "    for i in range(start_index, start_index + num_samples):\n",
    "        input_seq = encoder_input_data[i:i+1]\n",
    "        decoded = decode_sequence(input_seq)\n",
    "        print(f\"Sample {i}:\")\n",
    "        print(\"Input: \", input_texts[i])\n",
    "        print(\"Target:\", target_texts[i])\n",
    "        print(\"Predicted:\", decoded)\n",
    "        print(\"=\"*50)\n",
    "\n",
    "# predict 5 samples from index 0\n",
    "predict_samples(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3807409-d408-4504-a949-1d71d1418c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "smoothie = SmoothingFunction().method4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80645e58-d06b-43e1-87ef-c162b0239bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bleu_score(num_samples=100):\n",
    "    total_score = 0.0\n",
    "    individual_scores = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        input_seq = encoder_input_data[i:i+1]\n",
    "        decoded_sentence = decode_sequence(input_seq).strip().split()\n",
    "        reference_sentence = target_texts[i].replace('<start>', '').replace('<end>', '').strip().split()\n",
    "\n",
    "        score = sentence_bleu([reference_sentence], decoded_sentence, smoothing_function=smoothie)\n",
    "        individual_scores.append(score)\n",
    "        total_score += score\n",
    "\n",
    "    avg_bleu = total_score / num_samples\n",
    "    print(f\"\\nAverage BLEU score on {num_samples} samples: {avg_bleu:.4f}\")\n",
    "    return avg_bleu, individual_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e4be4e-d4c9-4210-8258-fc5eefcda73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bleu, scores = evaluate_bleu_score(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25180afc-414a-46ba-a3bd-6fef1ae13841",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b560c49e-9d93-47b4-a17a-e74c15d91528",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(\"Accuracy and Loss over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248718bf-15a8-4deb-9593-a38391260673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb411ac-8efc-484f-b26e-96ecb2212b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf88542-1d5c-43d6-888a-2d8dea036942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c274ba19-7255-40ce-b2a7-d25eddf1ae33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805d353-cad1-4e51-931c-418893da37e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88feabe1-a12c-4b8f-a89f-1de19b22b439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
